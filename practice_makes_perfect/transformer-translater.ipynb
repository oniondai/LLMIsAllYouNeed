{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7669478,"sourceType":"datasetVersion","datasetId":4473093}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n\nimport pandas as pd\n\ntrain_df = pd.read_csv(\"/kaggle/input/wmt-2014-english-german/wmt14_translate_de-en_train.csv\", lineterminator='\\n')\n\ntrain_df = train_df.sample(frac=0.2, random_state=42)\n\ntrain_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T22:14:20.707558Z","iopub.execute_input":"2025-06-29T22:14:20.707821Z","iopub.status.idle":"2025-06-29T22:14:56.438239Z","shell.execute_reply.started":"2025-06-29T22:14:20.707795Z","shell.execute_reply":"2025-06-29T22:14:56.437506Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\n\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r'([^\\w\\s])', r' \\1 ', text)\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\ntrain_df['de'] = train_df['de'].apply(clean_text)\ntrain_df['en'] = train_df['en'].apply(clean_text)\n\n\n\ntrain_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T22:14:56.43989Z","iopub.execute_input":"2025-06-29T22:14:56.440254Z","iopub.status.idle":"2025-06-29T22:15:28.07309Z","shell.execute_reply.started":"2025-06-29T22:14:56.440235Z","shell.execute_reply":"2025-06-29T22:15:28.072306Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"src_tokens_list = [s.split() for s in train_df['en'].tolist()]\ntgt_tokens_list = [s.split() for s in train_df['de'].tolist()]\n\nfrom collections import Counter\n\nsrc_counter = Counter(tok for sent in src_tokens_list for tok in sent)\ntgt_counter = Counter(tok for sent in tgt_tokens_list for tok in sent)\n\nsrc_vocab = {'<pad>': 0, '<unk>': 1, '<bos>': 2, '<eos>': 3}\nfor i, (tok, _) in enumerate(src_counter.most_common(), start=4):\n    src_vocab[tok] = i\n\ntgt_vocab = {'<pad>': 0, '<unk>': 1, '<bos>': 2, '<eos>': 3}\nfor i, (tok, _) in enumerate(tgt_counter.most_common(), start=4):\n    tgt_vocab[tok] = i\n\ninv_src_vocab = {i: w for w, i in src_vocab.items()}\ninv_tgt_vocab = {i: w for w, i in tgt_vocab.items()}\n\n#print(src_vocab)\n#print(tgt_vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T22:15:28.073887Z","iopub.execute_input":"2025-06-29T22:15:28.074124Z","iopub.status.idle":"2025-06-29T22:15:48.970894Z","shell.execute_reply.started":"2025-06-29T22:15:28.074104Z","shell.execute_reply":"2025-06-29T22:15:48.970342Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"max_len = 16 \n\ndef encode_and_pad(tokens, vocab, max_len):\n\n    ids = [vocab.get(tok, vocab['<unk>']) for tok in tokens]\n\n    ids = [vocab['<bos>']] + ids + [vocab['<eos>']]\n\n    ids = ids[:max_len]\n\n    if len(ids) < max_len:\n        ids += [vocab['<pad>']] * (max_len - len(ids))\n    return ids\n\nsrc_seqs = [encode_and_pad(tok_list, src_vocab, max_len) for tok_list in src_tokens_list]\ntgt_seqs = [encode_and_pad(tok_list, tgt_vocab, max_len) for tok_list in tgt_tokens_list]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T22:15:48.971824Z","iopub.execute_input":"2025-06-29T22:15:48.972028Z","iopub.status.idle":"2025-06-29T22:16:03.91751Z","shell.execute_reply.started":"2025-06-29T22:15:48.972012Z","shell.execute_reply":"2025-06-29T22:16:03.916821Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nsrc_tensor = torch.tensor(src_seqs, dtype=torch.long)  \ntgt_tensor = torch.tensor(tgt_seqs, dtype=torch.long)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T22:16:03.918287Z","iopub.execute_input":"2025-06-29T22:16:03.918591Z","iopub.status.idle":"2025-06-29T22:16:10.109031Z","shell.execute_reply.started":"2025-06-29T22:16:03.918563Z","shell.execute_reply":"2025-06-29T22:16:10.108392Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"d_model = 16\nnhead = 4\ndim_feedforward = 64\nmax_len = 16\n\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len):\n        super().__init__()\n        pe = torch.zeros(max_len, d_model)                # CPU'da oluştur\n        position = torch.arange(0, max_len).unsqueeze(1).float()  # (max_len, 1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float()\n                             * (-torch.log(torch.tensor(10000.0)) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)                     # çift indeks: sin\n        pe[:, 1::2] = torch.cos(position * div_term)                     # tek indeks: cos\n        self.register_buffer('pe', pe.unsqueeze(0))                      # (1, max_len, d_model)\n\n    def forward(self, x):\n        seq_len = x.size(1)\n        return x + self.pe[:, :seq_len, :]  \n    \n\nclass Encoder(nn.Module):\n    def __init__(self, d_model, nhead, dim_feedforward):\n        super().__init__()\n        self.self_attn = nn.MultiheadAttention(d_model, nhead, batch_first=True)\n        self.linear1 = nn.Linear(d_model, dim_feedforward)\n        self.linear2 = nn.Linear(dim_feedforward, d_model)\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.dropout = nn.Dropout(0.1)\n\n    def forward(self, src, src_mask=None, src_key_padding_mask=None):\n        attn_output, attn_weights = self.self_attn(src, src, src,\n                                                   attn_mask=src_mask,\n                                                   key_padding_mask=src_key_padding_mask)\n        src2 = self.norm1(src + self.dropout(attn_output))                 # Residual + Norm\n        ff_output = self.linear2(F.relu(self.linear1(src2)))               # FFN\n        output = self.norm2(src2 + self.dropout(ff_output))                # Residual + Norm\n        return output, attn_weights\n\n\nclass Decoder(nn.Module):\n    def __init__(self, d_model, nhead, dim_feedforward):\n        super().__init__()\n        self.self_attn = nn.MultiheadAttention(d_model, nhead, batch_first=True)\n        self.multihead_attn = nn.MultiheadAttention(d_model, nhead, batch_first=True)\n        self.linear1 = nn.Linear(d_model, dim_feedforward)\n        self.linear2 = nn.Linear(dim_feedforward, d_model)\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.norm3 = nn.LayerNorm(d_model)\n        self.dropout = nn.Dropout(0.1)\n\n    def forward(self, tgt, memory, tgt_mask=None,\n                memory_mask=None,\n                tgt_key_padding_mask=None,\n                memory_key_padding_mask=None):\n        attn_output1, attn_weights1 = self.self_attn(tgt, tgt, tgt,\n                                                     attn_mask=tgt_mask,\n                                                     key_padding_mask=tgt_key_padding_mask)\n        tgt2 = self.norm1(tgt + self.dropout(attn_output1))               # Maskeli Self-Attn\n        attn_output2, attn_weights2 = self.multihead_attn(tgt2, memory, memory,\n                                                          attn_mask=memory_mask,\n                                                          key_padding_mask=memory_key_padding_mask)\n        tgt3 = self.norm2(tgt2 + self.dropout(attn_output2))              # Cross-Attn\n        ff_output = self.linear2(F.relu(self.linear1(tgt3)))              # FFN\n        output = self.norm3(tgt3 + self.dropout(ff_output))               # Residual + Norm\n        return output, attn_weights1, attn_weights2\n\n\nclass Frenzy(nn.Module):\n    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, nhead, dim_feedforward, max_len):\n        super().__init__()\n        \n        self.src_embedding = nn.Embedding(src_vocab_size, d_model, padding_idx=src_vocab['<pad>'])\n        \n        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model, padding_idx=tgt_vocab['<pad>'])\n\n        self.pos_encoder = PositionalEncoding(d_model, max_len)\n        self.pos_decoder = PositionalEncoding(d_model, max_len)\n\n        self.encoder_layer = Encoder(d_model, nhead, dim_feedforward)\n        self.decoder_layer = Decoder(d_model, nhead, dim_feedforward)\n\n        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n\n    def generate_square_subsequent_mask(self, sz):\n        mask = torch.triu(torch.ones(sz, sz), diagonal=1).bool()\n        # Embedding layer'ın weight'ini kullanarak device'ı al\n        device = self.src_embedding.weight.device\n        return mask.to(device)\n\n    def forward(self, src_ids, tgt_ids):\n\n        batch_size, src_len = src_ids.size()\n        _, tgt_len = tgt_ids.size()\n\n        # 1) Encoder\n        src_emb = self.src_embedding(src_ids)             # (batch, src_len, d_model)\n        src_emb = self.pos_encoder(src_emb)\n        memory, _ = self.encoder_layer(src_emb)\n\n        # 2) Decoder\n        tgt_emb = self.tgt_embedding(tgt_ids)             # (batch, tgt_len, d_model)\n        tgt_emb = self.pos_decoder(tgt_emb)\n        tgt_mask = self.generate_square_subsequent_mask(tgt_len)  # (tgt_len, tgt_len)\n        output, _, _ = self.decoder_layer(tgt_emb, memory, tgt_mask=tgt_mask)\n\n        logits = self.fc_out(output)                      # (batch, tgt_len, tgt_vocab_size)\n        return logits\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T22:16:10.109764Z","iopub.execute_input":"2025-06-29T22:16:10.110192Z","iopub.status.idle":"2025-06-29T22:16:10.124684Z","shell.execute_reply.started":"2025-06-29T22:16:10.110172Z","shell.execute_reply":"2025-06-29T22:16:10.124022Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"src_vocab_size = len(src_vocab)\ntgt_vocab_size = len(tgt_vocab)\n\nmodel = Frenzy(\n    src_vocab_size=src_vocab_size,\n    tgt_vocab_size=tgt_vocab_size,\n    d_model=d_model,\n    nhead=nhead,\n    dim_feedforward=dim_feedforward,\n    max_len=max_len,\n)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\nif torch.cuda.device_count() > 1:\n    print(\"Birden fazla GPU bulundu. DataParallel aktif ediliyor.\")\n    model = nn.DataParallel(model)  \n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss(ignore_index=tgt_vocab['<pad>']) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T22:16:10.126646Z","iopub.execute_input":"2025-06-29T22:16:10.126854Z","iopub.status.idle":"2025-06-29T22:16:12.887313Z","shell.execute_reply.started":"2025-06-29T22:16:10.126838Z","shell.execute_reply":"2025-06-29T22:16:12.886536Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader\n\ndataset = TensorDataset(src_tensor, tgt_tensor)\n\ntrain_loader = DataLoader(\n    dataset,\n    batch_size=150,  # İki GPU için daha büyük batch (her GPU'da 16)\n    shuffle=True,\n    num_workers=4,  # GPU sayısına eşit\n    pin_memory=True,\n    persistent_workers=True,\n    drop_last=True  # Son batch'i at (GPU'lar arası eşit dağıtım için)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T22:16:12.888144Z","iopub.execute_input":"2025-06-29T22:16:12.888537Z","iopub.status.idle":"2025-06-29T22:16:12.893034Z","shell.execute_reply.started":"2025-06-29T22:16:12.888508Z","shell.execute_reply":"2025-06-29T22:16:12.89233Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.cuda.amp import autocast, GradScaler\n\nscaler = GradScaler()  \n\nnum_epochs = 30\nprint(\"\\n=== Training with FP16 (Mixed Precision) ===\")\n\nfor epoch in range(1, num_epochs + 1):\n    model.train()\n    total_loss = 0.0\n    batch_count = 0\n\n    for batch_idx, (src_batch, tgt_batch) in enumerate(train_loader):\n        current_batch = batch_idx + 1\n\n        src_batch = src_batch.to(device, non_blocking=True)\n        tgt_batch = tgt_batch.to(device, non_blocking=True)\n\n        decoder_input = tgt_batch[:, :-1]\n        target = tgt_batch[:, 1:]\n\n        optimizer.zero_grad()\n\n        with autocast(): \n            logits = model(src_batch, decoder_input)\n            logits = logits.reshape(-1, logits.size(-1))\n            loss = criterion(logits, target.reshape(-1))\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        total_loss += loss.item()\n        batch_count += 1\n\n        print(f\"\\rEpoch {epoch:02d} [{current_batch:04d}/{len(train_loader):04d}]  \"\n              f\"Batch Loss: {loss.item():.4f}\", end='')\n\n    avg_loss = total_loss / batch_count\n    print(f\"\\nEpoch {epoch:02d} Complete  |  Avg Loss: {avg_loss:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T22:16:12.893739Z","iopub.execute_input":"2025-06-29T22:16:12.893936Z","iopub.status.idle":"2025-06-30T06:08:29.429267Z","shell.execute_reply.started":"2025-06-29T22:16:12.89392Z","shell.execute_reply":"2025-06-30T06:08:29.428317Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def translate_sentence(model, sentence, src_vocab, tgt_vocab, inv_tgt_vocab, max_len=15):\n    model.eval()\n    with torch.no_grad():\n        # Preprocess\n        tokens = sentence.lower().split()\n        src_ids = [src_vocab.get(tok, src_vocab['<unk>']) for tok in tokens]\n        src_ids = [src_vocab['<bos>']] + src_ids + [src_vocab['<eos>']]\n        src_ids = src_ids[:max_len]\n        if len(src_ids) < max_len:\n            src_ids += [src_vocab['<pad>']] * (max_len - len(src_ids))\n        \n        src_tensor = torch.tensor([src_ids], dtype=torch.long).to(device)\n        \n        # Greedy decoding\n        tgt_ids = [tgt_vocab['<bos>']]\n        for _ in range(max_len-1):\n            tgt_tensor = torch.tensor([tgt_ids], dtype=torch.long).to(device)\n            \n            with torch.cuda.amp.autocast():\n                output = model(src_tensor, tgt_tensor)\n            \n            next_token = output[0, -1, :].argmax().item()\n            if next_token == tgt_vocab['<eos>']:\n                break\n            tgt_ids.append(next_token)\n        \n        # Decode\n        result = [inv_tgt_vocab.get(id, '<unk>') for id in tgt_ids[1:]]  # Skip <bos>\n        return ' '.join(result)\n\n# Test\ntest_sentence = \"hello world\"\ntranslation = translate_sentence(model, test_sentence, src_vocab, tgt_vocab, inv_tgt_vocab)\nprint(f\"Input: {test_sentence}\")\nprint(f\"Translation: {translation}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-30T06:08:29.430988Z","iopub.execute_input":"2025-06-30T06:08:29.43126Z","iopub.status.idle":"2025-06-30T06:08:29.540209Z","shell.execute_reply.started":"2025-06-30T06:08:29.431215Z","shell.execute_reply":"2025-06-30T06:08:29.539462Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}